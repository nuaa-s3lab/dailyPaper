(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{639:function(t,s,a){t.exports=a.p+"assets/img/image-20200405170552803.dbe1938a.png"},640:function(t,s,a){t.exports=a.p+"assets/img/image-20200405172515861.0451aa91.png"},641:function(t,s,a){t.exports=a.p+"assets/img/image-20200406180458795.a46fc3fc.png"},642:function(t,s,a){t.exports=a.p+"assets/img/image-20200406155113574.d3b2d020.png"},643:function(t,s,a){t.exports=a.p+"assets/img/image-20200407005553899.521027e0.png"},644:function(t,s,a){t.exports=a.p+"assets/img/image-20200407005525240.163224d5.png"},645:function(t,s,a){t.exports=a.p+"assets/img/image-20200407121814210.2140fea8.png"},646:function(t,s,a){t.exports=a.p+"assets/img/image-20210114230603301.86bb3e3f.png"},647:function(t,s,a){t.exports=a.p+"assets/img/image-20210114230643022.d1542478.png"},648:function(t,s,a){t.exports=a.p+"assets/img/image-20210114230756747.9b5fc1b9.png"},649:function(t,s,a){t.exports=a.p+"assets/img/image-20210114230955917.2076b749.png"},719:function(t,s,a){"use strict";a.r(s);var i=a(6),e=Object(i.a)({},(function(){var t=this,s=t.$createElement,i=t._self._c||s;return i("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[i("p",[t._v("大家好，今天为大家带来了发表在 "),i("strong",[t._v("USENIX Security 2019")]),t._v(" 的工作《XONN : XNOR-based Oblivious Deep Neural Network Inference》。他们实现一个了基于混淆电路协议的 BNN 框架。")]),t._v(" "),i("p",[t._v("目前 GC 和 BNN 的缺点如下：")]),t._v(" "),i("ol",[i("li",[t._v("Garbled Circuits(GC) 的缺点:乘法太低效")]),t._v(" "),i("li",[t._v("Binary Neural Network(BNN) 缺点:准确度太低。")])]),t._v(" "),i("p",[t._v("他们提出的 XONN 不仅对于 BNN 来说提升了准确度，而且提升了 GC 的运算效率，并且不需要进行乘法运算。")]),t._v(" "),i("p",[t._v("训练神经网络是一个很复杂的优化过程，在神经网络的不同隐含层中会有不同的局部最优解，他们选择的距离局部最优最近的(包括 weight 和 bias)二进制解当作最终解。")]),t._v(" "),i("p",[i("img",{attrs:{src:a(639),alt:"image-20200405170552803"}})]),t._v(" "),i("p",[t._v("使用二进制的输入 x 和二进制的 weight，使用 xor 进行运算，最后得到的 1 的个数就是最终结果。\n如果仅作如上的操作，整个神经网络的准确度会有很大的损失。")]),t._v(" "),i("p",[t._v("为了提升准确度，他们使用了两种方式：")]),t._v(" "),i("ol",[i("li",[t._v("使用 Scale layer 对输出进行缩放")]),t._v(" "),i("li",[t._v("对神经网络进行修建")])]),t._v(" "),i("p",[t._v("他们将对输出使用 Scale layer 进行缩放，然后设置缩放比例为 2 和 3 进行测试，准确率有所提升。")]),t._v(" "),i("p",[t._v("在此基础上，他们对神经网络进行修剪，并保持准确度，方式是降低对最终结果贡献率低的神经元的值。")]),t._v(" "),i("p",[i("img",{attrs:{src:a(640),alt:"image-20200405172515861"}})]),t._v(" "),i("h2",{attrs:{id:"oblivious-inference"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#oblivious-inference"}},[t._v("#")]),t._v(" Oblivious Inference")]),t._v(" "),i("h3",{attrs:{id:"integet-vdp"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#integet-vdp"}},[t._v("#")]),t._v(" Integet-VDP")]),t._v(" "),i("p",[t._v("在第一个卷积层中使用 Integet-VDP 的方式计算向量内积。因为第一个卷积层中的输入是未经二值化的 b 位 Integer，权重是经过二值化的 "),i("eq",[i("span",{staticClass:"katex"},[i("span",{staticClass:"katex-mathml"},[i("math",{attrs:{xmlns:"http://www.w3.org/1998/Math/MathML"}},[i("semantics",[i("mrow",[i("msub",[i("mi",[t._v("w")]),i("mi",[t._v("i")])],1),i("mo",[t._v("∈")]),i("mrow",[i("mo",{attrs:{stretchy:"false"}},[t._v("{")]),i("mo",[t._v("−")]),i("mn",[t._v("1")]),i("mo",{attrs:{separator:"true"}},[t._v(",")]),i("mn",[t._v("1")]),i("mo",{attrs:{stretchy:"false"}},[t._v("}")])],1)],1),i("annotation",{attrs:{encoding:"application/x-tex"}},[t._v("w_i\\in{\\lbrace-1,1\\rbrace}")])],1)],1)],1),i("span",{staticClass:"katex-html",attrs:{"aria-hidden":"true"}},[i("span",{staticClass:"base"},[i("span",{staticClass:"strut",staticStyle:{height:"0.6891em","vertical-align":"-0.15em"}}),i("span",{staticClass:"mord"},[i("span",{staticClass:"mord mathdefault",staticStyle:{"margin-right":"0.02691em"}},[t._v("w")]),i("span",{staticClass:"msupsub"},[i("span",{staticClass:"vlist-t vlist-t2"},[i("span",{staticClass:"vlist-r"},[i("span",{staticClass:"vlist",staticStyle:{height:"0.31166399999999994em"}},[i("span",{staticStyle:{top:"-2.5500000000000003em","margin-left":"-0.02691em","margin-right":"0.05em"}},[i("span",{staticClass:"pstrut",staticStyle:{height:"2.7em"}}),i("span",{staticClass:"sizing reset-size6 size3 mtight"},[i("span",{staticClass:"mord mathdefault mtight"},[t._v("i")])])])]),i("span",{staticClass:"vlist-s"},[t._v("​")])]),i("span",{staticClass:"vlist-r"},[i("span",{staticClass:"vlist",staticStyle:{height:"0.15em"}},[i("span")])])])])]),i("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}}),i("span",{staticClass:"mrel"},[t._v("∈")]),i("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.2777777777777778em"}})]),i("span",{staticClass:"base"},[i("span",{staticClass:"strut",staticStyle:{height:"1em","vertical-align":"-0.25em"}}),i("span",{staticClass:"mord"},[i("span",{staticClass:"mopen"},[t._v("{")]),i("span",{staticClass:"mord"},[t._v("−")]),i("span",{staticClass:"mord"},[t._v("1")]),i("span",{staticClass:"mpunct"},[t._v(",")]),i("span",{staticClass:"mspace",staticStyle:{"margin-right":"0.16666666666666666em"}}),i("span",{staticClass:"mord"},[t._v("1")]),i("span",{staticClass:"mclose"},[t._v("}")])])])])])]),t._v("。最后使用 popcont(x) 函数和 sign(x) 激活函数输出最终的二进制值。第一层卷积就相当于 OT 问题。")],1),t._v(" "),i("img",{staticStyle:{zoom:"33%"},attrs:{src:a(641),alt:"image-20200406180458795"}}),t._v(" "),i("img",{staticStyle:{zoom:"33%"},attrs:{src:a(642),alt:"image-20200406155113574"}}),t._v(" "),i("h3",{attrs:{id:"binary-vdp"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#binary-vdp"}},[t._v("#")]),t._v(" Binary-VDP")]),t._v(" "),i("p",[t._v("经过了第一层卷积之后，就可以使用 Binary-VDP(二进制向量积)来进行高速运算。")]),t._v(" "),i("img",{staticStyle:{zoom:"33%"},attrs:{src:a(643),alt:"image-20200407005553899"}}),t._v(" "),i("img",{staticStyle:{zoom:"33%"},attrs:{src:a(644),alt:"image-20200407005525240"}}),t._v(" "),i("h3",{attrs:{id:"pooling"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#pooling"}},[t._v("#")]),t._v(" pooling")]),t._v(" "),i("img",{staticStyle:{zoom:"33%"},attrs:{src:a(645),alt:"image-20200407121845031"}}),t._v(" "),i("p",[t._v("使用 or 运算来代替 max pooling。")]),t._v(" "),i("h2",{attrs:{id:"实验结果"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#实验结果"}},[t._v("#")]),t._v(" 实验结果")]),t._v(" "),i("p",[t._v("他们使用 MNIST 对使用 XONN 转化的 DNN 做了实验。转换的网络如下表")]),t._v(" "),i("img",{staticStyle:{zoom:"33%"},attrs:{src:a(646),alt:"image-20210114230603301"}}),t._v(" "),i("p",[t._v("运行的时的性能以及准确度：")]),t._v(" "),i("img",{staticStyle:{zoom:"33%"},attrs:{src:a(647),alt:"image-20210114230643022"}}),t._v(" "),i("p",[t._v("在 CIFAR-10 数据集的表现如下：")]),t._v(" "),i("img",{staticStyle:{zoom:"50%"},attrs:{src:a(648),alt:"image-20210114230756747"}}),t._v(" "),i("p",[t._v("除此之外，他们还对现实生活中医疗行业的数据进行了实验，表 7 和表 8 是数据集的介绍和实验结果：")]),t._v(" "),i("img",{staticStyle:{zoom:"33%"},attrs:{src:a(649),alt:"image-20210114230955917"}}),t._v(" "),i("h2",{attrs:{id:"总结"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),i("ol",[i("li",[t._v("BNN 非常适合 oblivious deep neural network")]),t._v(" "),i("li",[t._v("GC 带来的几点优势\n"),i("ol",[i("li",[t._v("客户端和服务器使用常数进行交互(取决于神经网络的层数)")]),t._v(" "),i("li",[t._v("可以升级为更健壮的安全模型")])])]),t._v(" "),i("li",[t._v("可以结合其他不同的 DL 算法来实现安全计算")])]),t._v(" "),i("ul",[i("li",[t._v("论文、录像、ppt 的链接："),i("a",{attrs:{href:"https://www.usenix.org/conference/usenixsecurity19/presentation/riazi",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://www.usenix.org/conference/usenixsecurity19/presentation/riazi"),i("OutboundLink")],1)])])])}),[],!1,null,null,null);s.default=e.exports}}]);